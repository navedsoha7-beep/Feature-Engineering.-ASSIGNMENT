{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Questions\n",
        "\n",
        "\n",
        "\n",
        "1.  What is a parameter?\n",
        "\n",
        "\n",
        "     - In Machine Learning (ML), a parameter is a variable that is learned from the training data and is used to make predictions or decisions.\n",
        "\n",
        "\n",
        "2. What is correlation?\n",
        " What does negative correlation mean?\n",
        "\n",
        "\n",
        "\n",
        "    - Correlation is a statistical measure that describes the relationship between two variables. It indicates how closely the variables move together, and in which direction.\n",
        "\n",
        "- Negative correlation: When one variable increases, the other variable tends to decrease.\n",
        "\n",
        "\n",
        "\n",
        "3.  Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "\n",
        "     - Machine Learning (ML) is a subset of artificial intelligence that enables systems to learn from data and improve their performance on a task without being explicitly programmed.\n",
        "\n",
        "The main components of Machine Learning are:\n",
        "\n",
        ". Data: The foundation of ML, which can be structured or unstructured.\n",
        ". Model: A mathematical representation of the relationships between variables in the data.\n",
        ". Algorithm: A set of rules and procedures used to train the model on the data.\n",
        ". Training: The process of adjusting the model's parameters to fit the data.\n",
        ". Evaluation: Assessing the performance of the trained model on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "4.  How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "\n",
        "\n",
        "      - A lower loss value typically indicates that the model is performing well, while a higher loss value suggests that the model is not fitting the data well.\n",
        "\n",
        "\n",
        "\n",
        "5.  What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "\n",
        "     - Continiuous are those which can take any value in the given data or interval while  categoral represents categories or groups.\n",
        "\n",
        "\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "\n",
        "    - Categorical variables require special handling in Machine Learning because most algorithms are designed to work with numerical data.\n",
        "\n",
        "\n",
        "    one hot encoding\n",
        "\n",
        "\n",
        "    label encoding\n",
        "\n",
        "\n",
        "\n",
        "    ordinal encoding\n",
        "\n",
        "\n",
        "\n",
        "    binary encodng\n",
        "\n",
        "\n",
        "    count encoding target encoding\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "7.  What do you mean by training and testing a dataset?\n",
        "\n",
        "\n",
        "    - Training data means training the data set while testing a data set means checking its accuracy according to the trained set.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "8.  What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     - sklearn.preprocessing is a module in scikit-learn, a popular Python library for Machine Learning. It provides various tools for data preprocessing, which is a crucial step in the Machine Learning pipeline.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "9.  What is a Test set?\n",
        "\n",
        "\n",
        "\n",
        "      - A Test set, also known as a holdout set, is a portion of the dataset that is not used during model training. Its primary purpose is to evaluate the performance of a trained model on unseen data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python?\n",
        " How do you approach a Machine Learning problem?\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "         - Splitting data into training and testing sets is crucial in Machine Learning. You can use libraries like Scikit-learn in Python, specifically the train_test_split function, to split your data. As for approaching a Machine Learning problem, it's all about understanding the problem, exploring your data, choosing the right model, and evaluating its performance. You might find more detailed guides and tutorials online that can walk you through specific steps and best practices.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "11.  Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        - it helps us in understanding a data so it is a very crucial process.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "12.  What is correlation?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      - It describes the realationship between two variables.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "13.  What does negative correlation mean?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      - Negative correlation: When one variable increases, the other variable tends to decrease.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "14.  How can you find correlation between variables in Python?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        - there are many libraries in phython to find correlatiom between variables in phython like seaborn and pandas.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      - Causation refers to a relationship between two variables where one variable (the cause) directly affects the other variable (the effect). In other words, causation implies that a change in one variable causes a change in the other variable.\n",
        "\n",
        "Correlation, on the other hand, refers to a statistical relationship between two variables, but it does not imply causation. Correlation can be positive (as one variable increases, the other variable also tends to increase), negative (as one variable increases, the other variable tends to decrease), or neutral (no relationship).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     - Optimizer\n",
        "An optimizer is a crucial component of the machine learning (ML) training process. Its primary function is to adjust the model's parameters to minimize the loss function, which measures the difference between the model's predictions and the actual true values.\n",
        "\n",
        "Types of Optimizers\n",
        "Here are some common types of optimizers:\n",
        "\n",
        ". Gradient Descent (GD)- Description: GD is a first-order optimization algorithm that uses the gradient of the loss function to update the model's parameters.\n",
        "- Example: Suppose we want to minimize the loss function L(w) = (w - 2)^2. The GD update rule would be w_new = w_old - learning_rate * 2 * (w_old - 2).\n",
        "\n",
        ". Stochastic Gradient Descent (SGD)- Description: SGD is a variant of GD that uses a single example from the training dataset to compute the gradient, rather than the entire dataset.\n",
        "- Example: In SGD, the update rule would be w_new = w_old - learning_rate * 2 * (w_old - y_true) * x, where x is the input feature and y_true is the true label.\n",
        "\n",
        ". Mini-Batch Gradient Descent- Description: This optimizer is a compromise between GD and SGD, using a small batch of examples to compute the gradient.\n",
        "- Example: If the batch size is 32, the update rule would be w_new = w_old - learning_rate * (1/32) * sum(2 * (w_old - y_true) * x), where the sum is taken over the 32 examples in the batch.\n",
        "\n",
        ". Momentum- Description: Momentum adds a fraction of the previous update to the current update, helping the optimizer escape local minima.\n",
        "- Example: The update rule would be v = momentum * v - learning_rate * gradient, w_new = w_old + v, where v is the velocity.\n",
        "\n",
        ". Nesterov Accelerated Gradient- Description: Nesterov Accelerated Gradient is a variant of momentum that incorporates the gradient of the future position.\n",
        "- Example: The update rule would be v = momentum * v - learning_rate * gradient, w_new = w_old + v - learning_rate * momentum * gradient.\n",
        "\n",
        ". RMSProp- Description: RMSProp divides the learning rate by an exponentially decaying average of squared gradients to normalize the update.\n",
        "- Example: The update rule would be cache = decay_rate * cache + (1 - decay_rate) * gradient^2, w_new = w_old - learning_rate * gradient / sqrt(cache + epsilon).\n",
        "\n",
        ". Adam- Description: Adam combines RMSProp and momentum, using both first and second moments of the gradient.\n",
        "- Example: The update rule would be m = beta1 * m + (1 - beta1) * gradient, v = beta2 * v + (1 - beta2) * gradient^2, w_new = w_old - learning_rate * m / sqrt(v + epsilon).\n",
        "\n",
        "Each optimizer has its strengths and weaknesses, and the choice of optimizer depends on the specific problem and dataset.\n",
        "\n",
        "These are just a few examples of the many optimizers available. The choice of optimizer can significantly impact the performance of the model, and experimentation is often necessary to find the best optimizer for a particular task.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      - The sklearn.linear_model module provides a simple and efficient way to implement linear models in Python, making it a popular choice for many Machine Learning tasks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "       -In scikit-learn, fit() is a method used to train a model on a given dataset. When you call fit() on a model object, it adjusts the model's parameters to best fit the training data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "           - In scikit-learn, predict() is a method used to make predictions on new, unseen data using a trained model. When you call predict() on a model object, it uses the learned parameters to generate predictions for the input data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "              - Continiuous are those which can take any value in the given data or interval while  categoral represents categories or groups.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          - Feature scaling, also known as feature normalization or standardization, is a technique used in Machine Learning to standardize the range of independent variables or features. It helps to prevent features with large ranges from dominating the model, which can lead to poor performance or slow training.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "22.  How do we perform scaling in Python?\n",
        "\n",
        "\n",
        "\n",
        "      - By creating the new features and modifying exsiting ones tha selecting the new feature.\n",
        "\n",
        "\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "     - Used to preprocess the existing data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      - In Python, you can use the train_test_split function from scikit-learn's model_selection module to split your data into training and testing sets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "25.  Explain data encoding?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      - Data encoding is the process of transforming categorical or textual data into numerical representations that can be processed by Machine Learning algorithms. This is necessary because many Machine Learning algorithms require numerical input data to learn and make predictions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x1hGmdyVSRvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be9sMe4wSO9M"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    }
  ]
}